Summary:
Seek to improve image captioning by combining Neural Network Encoder-Decoder modules with Attention Frameworks. Model learns to fix gaze on right objects while describing them using attention. Tested on Flickr8K, Flickr30K, MSCOCO to achieve state-of-art performance on BLEU and METEOR metrics

Strengths:
Previous works take last layer of convnets for image representations to get maximum information out of noise from image. However, potential loss of richer feature descriptions. They have used low level features while learning to steer the model to extract relevant information
Attention of both 'hard' and 'soft' forms was used to help the model generate the image description. Soft attention trained by standard backpropagation techniques, Hard attention stochastically trained using REINFORCE
Interpretable results - Learned alignments meet human intuition well qualitatively
No object detection is involved; Alignments are learned to pick up even abstract concepts from scratch

Weaknesses:

Reflections:

Most Interesting Thoughts:
